{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la carpeta donde se guardarán los archivos HTML\n",
    "folder_path = \"D:\\\\U\\\\7. Septimo\\\\RI\\\\ir24a\\\\week12\\\\data_c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la página principal de recetas\n",
    "base_url = \"https://www.allrecipes.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para descargar y guardar una receta\n",
    "def download_recipe(url, folder_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        recipe_title = soup.find(\"meta\", {\"property\": \"og:title\"})['content'].replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "        file_path = os.path.join(folder_path, f\"{recipe_title}.html\")\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el contenido de la página principal\n",
    "response = requests.get(base_url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # Encontrar todos los enlaces a recetas\n",
    "    recipe_links = soup.find_all('a', class_='tout__titleLink')\n",
    "\n",
    "    for link in recipe_links:\n",
    "        recipe_url = link['href']\n",
    "        download_recipe(recipe_url, folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descarga de recetas completada.\n"
     ]
    }
   ],
   "source": [
    "print(\"Descarga de recetas completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar los datos de cada archivo\n",
    "data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre todos los archivos en la carpeta\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".html\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            html_content = file.read()\n",
    "        \n",
    "        # Parsear el contenido HTML\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extraer título\n",
    "        title = soup.find(\"meta\", {\"property\": \"og:title\"})['content'] if soup.find(\"meta\", {\"property\": \"og:title\"}) else \"No Title\"\n",
    "\n",
    "        # Extraer descripción\n",
    "        description = soup.find('p', class_='article-subheading type--dog').text if soup.find('p', class_='article-subheading type--dog') else \"No Description\"\n",
    "\n",
    "        # Extraer pasos\n",
    "        steps = [item.text.strip() for item in soup.find_all(\"p\", class_='comp mntl-sc-block mntl-sc-block-html')]\n",
    "\n",
    "        # Extraer ingredientes\n",
    "        ingredients = [item.text.strip() for item in soup.find_all(\"li\", class_='mm-recipes-structured-ingredients__list-item')]\n",
    "        \n",
    "        # Agregar los datos a la lista\n",
    "        data_list.append({\n",
    "            \"Title\": title,\n",
    "            \"Description\": description,\n",
    "            \"Steps\": steps,\n",
    "            \"Ingredients\": ingredients\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con los datos de todos los archivos\n",
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el DataFrame resultante\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La pagina al tratar de descargar todo me bloqueo el acceso :("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
